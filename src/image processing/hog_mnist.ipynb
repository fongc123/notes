{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing: Histogram of Oriented Gradients (HOG) with MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from torchvision import transforms\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(input):\n",
    "    features = hog(\n",
    "        input,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2,2),\n",
    "    )\n",
    "\n",
    "    # convert numpy to tensor\n",
    "    return torch.from_numpy(features).type(torch.FloatTensor)\n",
    "\n",
    "# get training and test set\n",
    "mnist_train = MNIST(\"./data/\", download = True, transform = transform)\n",
    "mnist_test = MNIST(\"./data/\", train = False, download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = DataLoader(mnist_train, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(mnist_test, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0248, 0.0000, 0.0932,  ..., 0.1217, 0.2500, 0.1444],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1736, 0.1219, 0.0406],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0156, 0.0597, 0.0000]]) [[0. 0. 0. ... 0. 1. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "torch.Size([128, 144]) (128, 10)\n",
      "torch.Size([128, 10])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "multilabel_margin_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [103], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m output \u001b[39m=\u001b[39m svm(imgs)\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n\u001b[0;32m     24\u001b[0m \u001b[39m# backward pass\u001b[39;00m\n\u001b[0;32m     25\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\fongc\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\fongc\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:841\u001b[0m, in \u001b[0;36mMultiLabelMarginLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 841\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmultilabel_margin_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\fongc\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:3377\u001b[0m, in \u001b[0;36mmultilabel_margin_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3376\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m-> 3377\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mmultilabel_margin_loss(\u001b[39minput\u001b[39;49m, target, reduction_enum)\n",
      "\u001b[1;31mTypeError\u001b[0m: multilabel_margin_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# classification with SVM loss\n",
    "svm = nn.Linear(144, 10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(svm.parameters(), lr = 0.01)\n",
    "\n",
    "num_epochs = 2\n",
    "for it in range(num_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        # one hot encoder for loss\n",
    "        enc = OneHotEncoder(\n",
    "            handle_unknown = \"ignore\",\n",
    "            sparse = False,\n",
    "        )\n",
    "        labels = enc.fit_transform(labels.detach().numpy().reshape(-1, 1))\n",
    "\n",
    "        print(imgs, labels)\n",
    "        print(imgs.shape, labels.shape)\n",
    "\n",
    "        # forward pass\n",
    "        output = svm(imgs)\n",
    "\n",
    "        print(output.shape)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # update\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b13c84f26b03b81837babb7d6bb182b97bb46d822613cfd30489287e68eae110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
