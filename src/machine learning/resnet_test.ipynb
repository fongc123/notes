{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load CIFAR100 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761))\n",
    "])\n",
    "cifar100_train = datasets.CIFAR100(root='./data_cifar100', train=True, download=True, transform=transform)\n",
    "cifar100_test = datasets.CIFAR100(root='./data_cifar100', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data loader\n",
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(cifar100_train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(cifar100_test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar100_test.data[0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# set GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\fongc/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "# load ResNet50 model\n",
    "model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet50', pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do transfer learning on model\n",
    "model.fc = torch.nn.Linear(2048, 100)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers except the last one\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr = 0.001, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.576\n",
      "[1,   200] loss: 4.365\n",
      "[1,   300] loss: 4.201\n",
      "[2,   100] loss: 3.963\n",
      "[2,   200] loss: 3.879\n",
      "[2,   300] loss: 3.826\n",
      "[3,   100] loss: 3.715\n",
      "[3,   200] loss: 3.655\n",
      "[3,   300] loss: 3.618\n",
      "[4,   100] loss: 3.574\n",
      "[4,   200] loss: 3.539\n",
      "[4,   300] loss: 3.497\n",
      "[5,   100] loss: 3.441\n",
      "[5,   200] loss: 3.451\n",
      "[5,   300] loss: 3.447\n",
      "[6,   100] loss: 3.409\n",
      "[6,   200] loss: 3.384\n",
      "[6,   300] loss: 3.366\n",
      "[7,   100] loss: 3.341\n",
      "[7,   200] loss: 3.338\n",
      "[7,   300] loss: 3.330\n",
      "[8,   100] loss: 3.294\n",
      "[8,   200] loss: 3.315\n",
      "[8,   300] loss: 3.297\n",
      "[9,   100] loss: 3.258\n",
      "[9,   200] loss: 3.264\n",
      "[9,   300] loss: 3.263\n",
      "[10,   100] loss: 3.231\n",
      "[10,   200] loss: 3.243\n",
      "[10,   300] loss: 3.231\n",
      "[11,   100] loss: 3.214\n",
      "[11,   200] loss: 3.218\n",
      "[11,   300] loss: 3.214\n",
      "[12,   100] loss: 3.216\n",
      "[12,   200] loss: 3.216\n",
      "[12,   300] loss: 3.187\n",
      "[13,   100] loss: 3.164\n",
      "[13,   200] loss: 3.185\n",
      "[13,   300] loss: 3.193\n",
      "[14,   100] loss: 3.160\n",
      "[14,   200] loss: 3.163\n",
      "[14,   300] loss: 3.160\n",
      "[15,   100] loss: 3.147\n",
      "[15,   200] loss: 3.130\n",
      "[15,   300] loss: 3.132\n",
      "[16,   100] loss: 3.135\n",
      "[16,   200] loss: 3.140\n",
      "[16,   300] loss: 3.123\n",
      "[17,   100] loss: 3.114\n",
      "[17,   200] loss: 3.111\n",
      "[17,   300] loss: 3.115\n",
      "[18,   100] loss: 3.089\n",
      "[18,   200] loss: 3.102\n",
      "[18,   300] loss: 3.109\n",
      "[19,   100] loss: 3.078\n",
      "[19,   200] loss: 3.108\n",
      "[19,   300] loss: 3.085\n",
      "[20,   100] loss: 3.057\n",
      "[20,   200] loss: 3.085\n",
      "[20,   300] loss: 3.094\n",
      "[21,   100] loss: 3.097\n",
      "[21,   200] loss: 3.078\n",
      "[21,   300] loss: 3.064\n",
      "[22,   100] loss: 3.077\n",
      "[22,   200] loss: 3.049\n",
      "[22,   300] loss: 3.065\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2656\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b13c84f26b03b81837babb7d6bb182b97bb46d822613cfd30489287e68eae110"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
